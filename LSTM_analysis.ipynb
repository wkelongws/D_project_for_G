{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "from moviepy.editor import VideoFileClip,ImageSequenceClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, filter and smooth raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 2015 data\n",
      "load 2015 data\n"
     ]
    }
   ],
   "source": [
    "which_data = 'Data_2015_DES_I235E'\n",
    "(Traffic_2015,Weather_2015,data_2015) = pickle.load( open(which_data+\".p\", \"rb\" ) )\n",
    "year =  data_2015['y'][0][:4]\n",
    "print('load {} data'.format(year))\n",
    "\n",
    "which_data = 'Data_2016_DES_I235E'\n",
    "(Traffic_2016,Weather_2016,data_2016) = pickle.load( open(which_data+\".p\", \"rb\" ) )\n",
    "year =  data_2016['y'][0][:4]\n",
    "print('load {} data'.format(year))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_nan_with_local_mean(M_3d):\n",
    "    index = np.asarray(np.where(np.isnan(M_3d)))\n",
    "    for i in range(index.shape[1]):\n",
    "        span = 0\n",
    "        historical = M_3d[index[0,i],index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "        historical_mean = np.nanmean(historical)\n",
    "        stage_1_flag = True\n",
    "        count = 0 \n",
    "        while (not historical_mean>0) & stage_1_flag:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('1st ',count)\n",
    "            if index[0,i]-span<0:\n",
    "                historical = M_3d[0:index[0,i]+1+span+span,index[1,i],index[2,i]]\n",
    "            elif index[0,i]+1+span>M_3d.shape[0]:\n",
    "                historical = M_3d[-1-span-span:,index[1,i],index[2,i]]\n",
    "            else:\n",
    "                historical = M_3d[index[0,i]-span:index[0,i]+1+span,index[1,i],index[2,i]]\n",
    "            historical_mean = np.nanmean(historical)\n",
    "            span+=1\n",
    "            if 2*span>M_3d.shape[0]:\n",
    "                stage_1_flag = False\n",
    "        span = 0\n",
    "        count = 0 \n",
    "        while not historical_mean>0:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('2nd ',count)\n",
    "            if index[2,i]-span<0:\n",
    "                historical = M_3d[:,index[1,i],0:index[2,i]+1+span+span]\n",
    "            elif index[2,i]+1+span>M_3d.shape[2]:\n",
    "                historical = M_3d[:,index[1,i],-1-span-span:]\n",
    "            else:\n",
    "                historical = M_3d[:,index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "            historical_mean = np.nanmean(historical)\n",
    "            span+=1\n",
    "#         print(historical_mean)\n",
    "\n",
    "        span = 0\n",
    "        count = 0 \n",
    "        local = M_3d[index[0,i],index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "        local_mean = np.nanmean(local)\n",
    "        stage_1_flag = True\n",
    "        while (not local_mean>0) & stage_1_flag:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('3rd ',count)\n",
    "            if index[2,i]-span<0:\n",
    "                local = M_3d[index[0,i],index[1,i],0:index[2,i]+1+span+span]\n",
    "            elif index[2,i]+1+span>M_3d.shape[2]:\n",
    "                local = M_3d[index[0,i],index[1,i],-1-span-span:]\n",
    "            else:\n",
    "                local = M_3d[index[0,i],index[1,i],index[2,i]-span:index[2,i]+1+span]\n",
    "            local_mean = np.nanmean(local)\n",
    "            span+=1\n",
    "            if 2*span>M_3d.shape[2]:\n",
    "                stage_1_flag = False\n",
    "        \n",
    "        span = 0\n",
    "        count = 0 \n",
    "        while not local_mean>0:\n",
    "            count+=1\n",
    "            if count > 1000:\n",
    "                print('4th ',count)\n",
    "            if index[1,i]-span<0:\n",
    "                local = M_3d[index[0,i],0:index[1,i]+1+span+span,:]\n",
    "            elif index[1,i]+1+span>M_3d.shape[1]:\n",
    "                local = M_3d[index[0,i],-1-span-span:,:]\n",
    "            else:\n",
    "                local = M_3d[index[0,i],index[1,i]-span:index[1,i]+1+span,:]\n",
    "            local_mean = np.nanmean(local)\n",
    "            span+=1\n",
    "        \n",
    "#         print(local_mean)\n",
    "        M_3d[index[0,i],index[1,i],index[2,i]] = 0.7*local_mean + 0.3*historical_mean\n",
    "    return M_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter traffic data .....\n",
      "Done\n",
      "Smooth traffic data .....\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def volume_smoothing(Volume,top_threshold = 400):\n",
    "    Volume[Volume>top_threshold] = nan\n",
    "    Volume = replace_nan_with_local_mean(Volume)\n",
    "    return Volume\n",
    "\n",
    "def speed_smoothing(Speed,top_threshold = 120):\n",
    "    Speed[Speed>top_threshold] = nan\n",
    "    Speed = replace_nan_with_local_mean(Speed)\n",
    "    Speed[Speed == 0] = nan\n",
    "    Speed = replace_nan_with_local_mean(Speed)\n",
    "    return Speed\n",
    "\n",
    "print('Filter traffic data .....')\n",
    "# Traffic_2015[:,:,:,0] = speed_smoothing(Traffic_2015[:,:,:,0])\n",
    "# Traffic_2015[:,:,:,1] = volume_smoothing(Traffic_2015[:,:,:,1])\n",
    "\n",
    "# Traffic_2016[:,:,:,0] = speed_smoothing(Traffic_2016[:,:,:,0])\n",
    "# Traffic_2016[:,:,:,1] = volume_smoothing(Traffic_2016[:,:,:,1])\n",
    "print('Done')\n",
    "\n",
    "def moving_avg_batch(data,window_length=5):\n",
    "    data_new = np.zeros(data.shape)\n",
    "    for i in range(window_length):\n",
    "        data_shift = np.copy(data)\n",
    "        data_shift[:,:,i:]=data[:,:,:data.shape[2]-i]\n",
    "        data_new += data_shift\n",
    "    return data_new/window_length\n",
    "\n",
    "def data_smoothing_moving_avg(data,window_length=5):\n",
    "    data_new = np.copy(data)\n",
    "    if len(data.shape)==4:\n",
    "        for i in range(data.shape[-1]):\n",
    "            data_new[:,:,:,i] = moving_avg_batch(data[:,:,:,i],window_length=window_length)\n",
    "    if len(data.shape)==3:\n",
    "        data_new = moving_avg_batch(data,window_length=window_length)\n",
    "    return data_new\n",
    "\n",
    "print('Smooth traffic data .....')\n",
    "# Traffic_2015 = data_smoothing_moving_avg(Traffic_2015)\n",
    "# Traffic_2016 = data_smoothing_moving_avg(Traffic_2016)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump( (Traffic_2015,Weather_2015,data_2015), open( 'Data_2015_DES_I235E'+'_filter_smooth.p', \"wb\" ) )\n",
    "# pickle.dump( (Traffic_2016,Weather_2016,data_2016), open( 'Data_2016_DES_I235E'+'_filter_smooth.p', \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import saved smoothed data (start from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 data loaded\n",
      "2016 data loaded\n"
     ]
    }
   ],
   "source": [
    "which_data = 'Data_2015_DES_I235E'\n",
    "(Traffic_2015,Weather_2015,data_2015) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2015['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "which_data = 'Data_2016_DES_I235E'\n",
    "(Traffic_2016,Weather_2016,data_2016) = pickle.load( open(which_data+\"_filter_smooth.p\", \"rb\" ) )\n",
    "year =  data_2016['y'][0][:4]\n",
    "print('{} data loaded'.format(year))\n",
    "\n",
    "data = pd.concat([data_2015,data_2016],ignore_index=True)\n",
    "Traffic = np.concatenate([Traffic_2015, Traffic_2016],axis = 0)\n",
    "Weather_5min = np.concatenate([Weather_2015, Weather_2016],axis = 0)\n",
    "Weather = np.zeros([Weather_5min.shape[0],Weather_5min.shape[1],Weather_5min.shape[2]*5,Weather_5min.shape[3]])\n",
    "for i in range(Weather.shape[2]):\n",
    "    Weather[:,:,i,:] = Weather_5min[:,:,int(i/5),:]\n",
    "Weather = np.delete(Weather,1,axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Data Base\n",
    "* ### Multi-output: each sample includes {'traffic':(15,1439,3),'weather':(15,1439,10),'history':(6,15,1439,3),'label':(15,1439)}\n",
    "* ### Single-output: each sample includes {'traffic':(15,1439,3),'weather':(15,1439,10),'history':(6,15,1439,3),'label':(1439,)}\n",
    "* ### note: in 'history', non-existing days in database are represented in nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_SpeedPrediction_database_output_single_sensor(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6, target_sensor = 13):\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "        self.target_sensor = target_sensor\n",
    "#         print(self.__len__())\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        \n",
    "        Traffic_today = self.Traffic[idx,:,:-1,:]\n",
    "        Weather_today = self.Weather[idx,:,:-1,:]\n",
    "        Traffic_history = 0\n",
    "        Traffic_output = self.Traffic[idx,self.target_sensor,1:,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[idx]['dayofweek']\n",
    "        data_sub = self.data[:idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dlen(sameday_in_history)ayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "        Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[i] = self.Traffic[sameday_in_near_history[i]]\n",
    "        \n",
    "        sample = {'traffic': Traffic_today, 'weather': Weather_today, 'history': Traffic_history, 'label': Traffic_output}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "     \n",
    "class LSTM_SpeedPrediction_database_output_multi_sensor(Dataset):\n",
    "    def __init__(self, Traffic, Weather, data, transform=None, look_back = 6):\n",
    "\n",
    "        self.Traffic = Traffic\n",
    "        self.Weather = Weather\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.look_back = look_back\n",
    "#         printdb_trans_1 = Dataset_NVIDIA_1(annotation_list,frame_list,transform = PerspectiveTransform(MAP_FILE, world_origin, pixel_ratio, PMAT_FILE))(self.__len__())\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        assert idx < self.__len__(),'idx out of dataset index boundary'\n",
    "        Traffic_today = self.Traffic[idx,:,:-1,:]\n",
    "        Weather_today = self.Weather[idx,:,:-1,:]\n",
    "        Traffic_history = 0 \n",
    "        Traffic_output = self.Traffic[idx,:,1:,0]\n",
    "        \n",
    "        dayofweek = self.data.loc[idx]['dayofweek']\n",
    "        data_sub = self.data[:idx]\n",
    "        sameday_in_history = data_sub.index[data_sub['dayofweek'] == dayofweek].tolist()\n",
    "        \n",
    "        Traffic_history = np.full((self.look_back,)+self.Traffic.shape[1:], np.nan)\n",
    "#         print(len(sameday_in_history))\n",
    "        sameday_in_near_history = sameday_in_history[-self.look_back:]\n",
    "#         print(len(sameday_in_near_history))\n",
    "        \n",
    "        for i in range(len(sameday_in_near_history)):\n",
    "            Traffic_history[i] = self.Traffic[sameday_in_near_history[i]]\n",
    "        \n",
    "        sample = {'traffic': torch.Tensor(Traffic_today),'weather': torch.Tensor(Weather_today), 'history': torch.Tensor(Traffic_history), 'label': torch.Tensor(Traffic_output)} # \n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic, Weather, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X                      20161216Dir1.csv\n",
      "y             20161216_Traffic_Dir1.csv\n",
      "day                            20161216\n",
      "date                2016-12-16 00:00:00\n",
      "dayofweek                             4\n",
      "weekofyear                           50\n",
      "month                                12\n",
      "dayofyear                           351\n",
      "Name: 431, dtype: object\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86f63c4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 431  # test: [417,420,431]\n",
    "print(data.loc[idx])\n",
    "\n",
    "def vis_one_day_traffic_speed(speed):\n",
    "    plt.pcolor(speed,cmap=my_cmap, vmin=20, vmax=70)\n",
    "    \n",
    "# vis_one_day_traffic_speed(db[257]['label'])\n",
    "print(type(db[idx]['traffic']))\n",
    "vis_one_day_traffic_speed(db[idx]['traffic'][:,:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_test = data.loc[[417,420,431]]\n",
    "# data_test = data_test.reset_index()\n",
    "\n",
    "# data_train = data\n",
    "# data_train = data_train.drop([417,420,431])\n",
    "# data_train = data_train.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader: load sample from database in batch\n",
    "\n",
    "## batch added one more dimension to the left\n",
    "\n",
    "## in case of multi-output and batch = 10, each sample:\n",
    "\n",
    "## {'traffic':(10,15,1439,3),'weather':(10,15,1439,10),'history':(10,6,15,1439,3),'label':(10,15,1439)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data[:-30]\n",
    "data_train = data_train.reset_index()\n",
    "\n",
    "data_val = data[-61:]\n",
    "data_val = data_val.reset_index()\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic[:-30], Weather[:-30], data_train)\n",
    "dataset['val'] = LSTM_SpeedPrediction_database_output_multi_sensor(Traffic[-61:], Weather[-61:], data_val)\n",
    "\n",
    "dataset_sizes = {x: len(dataset[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size=200,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in dataloaders['train']:\n",
    "#     print('traffic: ',sample['traffic'].shape)\n",
    "#     print('weather: ',sample['weather'].shape)\n",
    "#     print('history: ',sample['history'].shape)\n",
    "#     print('label: ',sample['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://github.com/wkelongws/iemgrid'''\n",
    "'''Weather: 0:tmpc 1:dwpc 2:smps 3:drct 4:vsby 5:roadtmpc 6:srad 7:snwd 8:pcpn '''\n",
    "\n",
    "Traffic_max = []\n",
    "Traffic_min = []\n",
    "Weather_max = []\n",
    "Weather_min = []\n",
    "\n",
    "for i in range(Traffic.shape[-1]):\n",
    "#     print(i,'max: ',np.max(Traffic[:,:,:,i]))\n",
    "    Traffic_max.append(np.max(Traffic[:,:,:,i]))\n",
    "#     print(i,'mean: ',np.mean(Traffic[:,:,:,i]))\n",
    "#     print(i,'min: ',np.min(Traffic[:,:,:,i]))\n",
    "    Traffic_min.append(np.min(Traffic[:,:,:,i]))\n",
    "for i in range(Weather.shape[-1]):\n",
    "#     print(i,'max: ',np.max(Weather[:,:,:,i]))\n",
    "    Weather_max.append(np.max(Weather[:,:,:,i]))\n",
    "#     print(i,'mean: ',np.mean(Weather[:,:,:,i]))\n",
    "#     print(i,'min: ',np.min(Weather[:,:,:,i]))\n",
    "    Weather_min.append(np.min(Weather[:,:,:,i]))\n",
    "    \n",
    "Min_Max = (Traffic_max,Traffic_min,Weather_max,Weather_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-25.0, -29.0, 0.0, 0.0, 0.0, -20.399999999999999, 0.0, 0.0, -36.0]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min_Max[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Prediction Net\n",
    "## Normalization on the fly. Normalize all numbers ~ (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_Short_Term_Speed_Pred_Net(nn.Module):\n",
    "    def __init__(self, input_dim_today, input_dim_history, output_single_sensor = False, \\\n",
    "                 hidden_dim = 16,use_['traffic'].shapegpu = False, use_volume_and_occup = False, \\\n",
    "                 use_weather = False, use_history = True, input_feature = 'raw', Min_Max = Min_Max):\n",
    "        super(LSTM_Short_Term_Speed_Pred_Net, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim_today = input_dim_today\n",
    "        self.input_dim_history = input_dim_history\n",
    "        self.out_dim = 15\n",
    "        if output_single_sensor:\n",
    "            self.out_dim = out_dim = 1\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        self.use_volume_and_occup = use_volume_and_occup\n",
    "        self.use_weather = use_weather\n",
    "        self.use_history = use_history\n",
    "        assert input_feature in ['raw','linear','CNN'], 'wrong choice for input_feature'\n",
    "        self.input_feature = input_feature # ['raw','linear','CNN']\n",
    "        \n",
    "        '''for on-fly normalization'''\n",
    "        self.Traffic_max = Min_Max[0]\n",
    "        self.Traffic_min = Min_Max[1]\n",
    "        self.Weather_max = Min_Max[2]\n",
    "        self.Weather_min = Min_Max[3]\n",
    "        \n",
    "        if self.input_feature == 'cnn':\n",
    "            self.CNN_feature_extract = nn.Conv2d(16, 33, (5, 1), stride=(1, 1))\n",
    "            if self.use_volume_and_occup:\n",
    "                self.CNN_feature_extract = nn.Conv2d(16, 33, (5, 3), stride=(1, 1))\n",
    "            if self.use_weather:\n",
    "                self.CNN_feature_extract = nn.Conv2d(16, 33, (5, 12), stride=(1, 1))\n",
    "                \n",
    "        self.lstm_today = nn.LSTMCell(input_dim_today, hidden_dim)\n",
    "        self.lstm_history = nn.LSTMCell(input_dim_history, hidden_dim)\n",
    "        self.linear_out = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "    def init_hidden(self,input_sample):\n",
    "        \n",
    "        batch_size = input_sample['traffic'].shape[0]\n",
    "        if self.use_gpu:\n",
    "            return Variable(torch.zeros(batch_size, self.hidden_dim).cuda(), requires_grad=False)\n",
    "        return Variable(torch.zeros(batch_size, self.hidden_dim), requires_grad=False)\n",
    "\n",
    "    def forward(self, input_sample, future = 0):\n",
    "        \n",
    "        '''reconstruct data from sample'''\n",
    "        traffic = input_sample['traffic']\n",
    "        weather = input_sample['weather']\n",
    "        history = input_sample['history']\n",
    "        label = input_sample['label']\n",
    "        \n",
    "        '''normalize'''\n",
    "        label = (label - self.Traffic_min[0])/(self.Traffic_max[0]-self.Traffic_min[0])\n",
    "        for i in range(traffic.shape[-1]):\n",
    "            traffic[:,:,:,i] = (traffic[:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "            history[:,:,:,:,i] = (history[:,:,:,i]-self.Traffic_min[i])/(self.Traffic_max[i]-self.Traffic_min[i])\n",
    "        for i in range(weather.shape[-1]):\n",
    "            weather[:,:,:,i] = (weather[:,:,:,i]-self.Weather_min[i])/(self.Weather_max[i]-self.Weather_min[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "        outputs = []\n",
    "        hidden_state_today = self.init_hidden(input_sample)\n",
    "        cell_state_today = self.init_hidden(input_sample)\n",
    "        hidden_state_history = self.init_hidden(input_sample)\n",
    "        cell_state_history = self.init_hidden(input_sample)\n",
    "        \n",
    "        for i in range(input.data.shape[0]):\n",
    "            input_t = input[i]\n",
    "#             print('i: ',i)\n",
    "#             print('input_t: ',input_t.data.shape)\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "#         print('outputs.data.shape: ',outputs.data.shape)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n",
      "traffic:  torch.Size([200, 15, 1439, 3])\n",
      "weather:  torch.Size([200, 15, 1439, 9])\n",
      "history:  torch.Size([200, 6, 15, 1440, 3])\n",
      "label:  torch.Size([200, 15, 1439])\n",
      "<class 'torch.FloatTensor'>\n",
      "traffic:  torch.Size([200, 15, 1439, 3])\n",
      "weather:  torch.Size([200, 15, 1439, 9])\n",
      "history:  torch.Size([200, 6, 15, 1440, 3])\n",
      "label:  torch.Size([200, 15, 1439])\n",
      "<class 'torch.FloatTensor'>\n",
      "traffic:  torch.Size([17, 15, 1439, 3])\n",
      "weather:  torch.Size([17, 15, 1439, 9])\n",
      "history:  torch.Size([17, 6, 15, 1440, 3])\n",
      "label:  torch.Size([17, 15, 1439])\n"
     ]
    }
   ],
   "source": [
    "for sample in dataloaders['train']:\n",
    "#     b = sample['traffic'].shape\n",
    "    print(type(sample['traffic']))\n",
    "    print('traffic: ',sample['traffic'].shape)\n",
    "    print('weather: ',sample['weather'].shape)\n",
    "    print('history: ',sample['history'].shape)\n",
    "    print('label: ',sample['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1  2\n",
       "  3  4\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2  5\n",
       "  6  8\n",
       "[torch.FloatTensor of size 2x2x2]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[[1,2],[3,4]],[[2,5],[6,8]]])).float()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0.0000  0.1429\n",
       "  0.2857  0.4286\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.1429  0.5714\n",
       "  0.7143  1.0000\n",
       "[torch.FloatTensor of size 2x2x2]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a-1)/(8-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50, 100])\n",
      "torch.Size([20, 33, 26, 100])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = autograd.Variable(torch.randn(20, 16, 50, 100))\n",
    "output = m(input)\n",
    "print(input.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.variable.Variable"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input =  Variable(torch.from_numpy(np.zeros((10,1,15,15))))\n",
    "type(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.DoubleTensor"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.from_numpy(np.random.randn(10,1,15,15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 15, 3])\n",
      "torch.Size([10, 3, 11, 1])\n"
     ]
    }
   ],
   "source": [
    "input =  Variable(torch.from_numpy(np.random.randn(10,1,15,3)).float())\n",
    "cnn = nn.Conv2d(1, 3, (5, 3), stride=(1, 1))\n",
    "output = cnn(input)\n",
    "print(input.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customized_loss(preds, targets):\n",
    "    \n",
    "    preds = preds.view(preds.data.shape[0]*preds.data.shape[1],-1)\n",
    "    targets = targets.view(targets.data.shape[0]*targets.data.shape[1],-1)\n",
    "    \n",
    "    pdist = nn.PairwiseDistance(p=2)\n",
    "    \n",
    "    output = pdist(preds, targets)\n",
    "\n",
    "    loss = sum(output)/output.data.shape[0]\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False\n",
    "\n",
    "model = LSTM_perVehiclePrediction_Net(hidden_dim = 51, traj_dim = 2, use_gpu = use_gpu)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LSTM_perVehiclePrediction_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=10):\n",
    "    since = time.time()\n",
    "#     timeSince(since)\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_loss = 100000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "#                 print(data)\n",
    "                # get the inputs\n",
    "                inputs = data['traj']\n",
    "                labels = data['target']\n",
    "                inputs = inputs.permute(1,0,2)\n",
    "#                 print('labels.shape: ',labels.shape)\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())model_ft = train_LSTM_perVehiclePrediction_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=2000)\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Also, we need to clear out the hidden state of the LSTM,\n",
    "                # detaching it from its history on the last instance.\n",
    "#                 model.hidden = model.init_hidden()\n",
    "                \n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # loss function\n",
    "                loss = customized_loss(outputs, labels)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} total elapsed time: {}'.format(phase, epoch_loss, timeSince(since)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = model.state_dict()\n",
    "                torch.save(best_model_wts, 'Best_LSTM_Weights')\n",
    "                print('Weights saved to \"Best_LSTM_Weights\"')\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Training complete in {}'.format(timeSince(since)))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model, 'Model_with_Best_LSTM_Weights')\n",
    "    print('Model saved to \"Model_with_Best_LSTM_Weights\"')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ft = train_LSTM_perVehiclePrediction_Net(model,dataloaders, criterion, optimizer, dataset_sizes, num_epochs=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
